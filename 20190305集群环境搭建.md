# 3. Tips
Hadoop集群环境搭建---- 本文大部分来源于《Hadoop大数据挖掘从入门到进阶实战（视频教学版）》 邓杰编著

在云上租了5台学生服务器，系统都是CentOS7.5的，硬件配置如下


|**主机名**|    **角色**   |**内存**|**CPU**|
|--------|----------------|--------|-------|
|  nna  |NameNode Active  |  4GB   |  2核  |
|  nns  |NameNode Standby |  2GB   |  1核  |
|  dn1  |DataNode         |  2GB   |  1核  |
|  dn2  |DataNode         |  2GB   |  1核  |
|  dn3  |DataNode         |  2GB   |  1核  |




在云上改Centos7的主机名命令如下：
![改主机名](https://github.com/echofoo/ARTS/blob/master/pic/%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D.png)

## 1.为所有主机创建Hadoop账号(推荐使用root)
```bash
# 建名为hadoop的账号
useradd hadoop
# 名为hadoop的账号设置密码
passwd hadoop

根据系统提示设置登录密码，接着给hadoop账号设置免密码登录权限：
```bash
# sudoers文件赋予写权限
chmod +w /etc/sudoers
# 打开sudoers 文件并进行编辑
vi /etc/sudoers
# 在sudoers文件中添加以下内容
hadoop ALL=(root)NOPASSWD:ALL
# 最后保存内容后退出，并取消sudoers文件的写权限
chmod -w /etc/sudoers
```


所有安装组件[下载地址](https://github.com/echofoo/ARTS/blob/master/20190305Hadoop%E9%9B%86%E7%BE%A4%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80.md)

在hadoop用户下，在nna节点上安装JDK，并同步到其他4个节点上（这里都将主机成为“节点”）
## 2 安装配置jdk
### 1 卸载CentOS操作系统自带的JDK环境（云上的系统不自带JDK）

```bash
# 查找Java安装依赖库
rpm -qa | grep Java
# 卸载Java依赖库
yum -y remove Java*
```
### 2 将下载的JDK安装包解压缩到指定目录下 

```bash
# 解压JDK安装包到当前目录 
tar -zxvf jdk-8u144-linux-x64.tar.gz
# 移动JDK到 /data/soft 目录下，并改名位jdk
mv jdk-8u144-linux-x64 /data/soft/jdk
```

### 3 编辑环境变量，具体操作命令如下

```bash
# 打开全局环境变量文件 
vi /etc/profile
# 添加具体内容如下
export JAVA_HOME=/data/soft/jdk
export PATH=$PATH:$JAVA_HOME/bin
# 编辑完成后按ESC键，输入:wq 保存并退出
```
**注意**：等号左右不能有空格。

 ### 4 若要使刚刚配置的文件立即生效，执行如下命令 
 ```bash
 # 使用source或者英文点(.)命令，立即生效配置文件
 souce /etc/profile
 ```
 
 ### 5 验证安装JDK环境是否成功，具体操作命令如下：
 ```bash
 # Java语言版本验证命令
 java -version
 ```
 
 
 ### 6 同步安装包
 将jdk文件夹复制到其他主机
 ```bash
 #Linux 传输命令（例中是将nna节点的文件复制到nns上）
 scp -r /data/soft/jdk hadoop@nns:/data/soft
 ```
 没有配置好hosts文件的，可以用具体的IP地址取代上面命令中的nns, 即hadoop@nns 换成 hadoop@192.168.11.102 。
 在这里可能会提示：permission denied. 原因是目标节点的hadoop用户没有对/data目录写的权限，可以用以下命令添加该权限
 ```bash
 [hadoop@nns root]sudo chmod 777 /data 
 ```
 下面将介绍hosts配置
 
 
 ## 3. 配置hosts系统文件
 五个节点中的hosts配置都相同，用别名取代IP，方便后续的操作和配置，具体配置hosts文件的命令如下：
 ```bash
 # 打开hosts文件
 vi /etc/hosts 
 # 在hosts文件中添加以下内容
 192.168.11.101 nna
 192.168.11.102 nns
 192.168.11.103 dn1
 192.168.11.104 dn2
 192.168.11.105 dn3
 # 编辑完成后保存并退出
 ```
 完成该节点hosts文件的编辑后，可以用scp命令将nna节点上的hosts文件分发到其他节点，具体命令如下：
 ```bash
 # 以传输到nns节点为例
 scp /etc/hosts hadoop@nns: /etc
 ```
 
 
 ## 4.安装SSH
### 1.创建密钥
Hadoop集群需要保证各个节点互相通信，这里需要用到SSH，具体安装步骤及操作命令如下：
#生成该节点的私钥和公钥
ssh-keygen -t rsa
输入上述命令后，只需要按回车键，不需要设置任何信息，命令操作结束后会在~/.ssh/目录下生成对应的私钥和公钥等文件。
### 2.认证授权

防火墙
https://blog.csdn.net/qq_35868412/article/details/86602636
https://blog.csdn.net/alex2917/article/details/50900275


## 5.Zookeeper部署
### 1. 下载并解压
### 2. 创建状态数据存储文件夹
mkdir -p /data/soft/zkdata
### 3.配置zoo.cfg文件
dataDir=/data/soft/zkdata

clientPort=2181

server.1=dn1:2888:3888
server.2=dn1:2888:3888
server.3=dn1:2888:3888

### 4.配置注意事项
在配置的dataDir目录下（本例中即/data/soft/zkdata目录下）创建一个myid文件，文件里面的数字在各个节点唯一，范围在0~255之间，且应该与server.X=dn1:2888:3888中的X代表的数字一致。

### 5. 云服务器的两个额外配置
由于云服务器无法真正关闭真实主机的防火墙，也无法访问真实主机的ip（给的所谓弹性公网ip并不是真实主机ip），所以还应添加如下两个操作：
* 将云上开放2181，2888，3888端口，将这三个端口加入安全组(实例->更多->安全组)。具体操作参照https://help.aliyun.com/document_detail/25443.html?spm=a2c4g.11186623.2.27.c7af71afHAp93s 或 https://jingyan.baidu.com/album/03b2f78c31bdea5ea237ae88.html?picindex=1
* 在zoo.cfg添加一行语句：`quorumListenOnAllIPs=true`,具体原因参照：https://blog.csdn.net/u014284000/article/details/74508963

### 6.配置并生效环境变量

### 7.启动并验证
```bash
zkServer.sh start
zkServer.sh status
```

以上操作均在3个datanode节点上执行。可以使用scp命令将下载安装包或刚刚设置的配置文件分发到其他节点。
